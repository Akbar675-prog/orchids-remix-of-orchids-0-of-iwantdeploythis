import { openproviders } from "@/lib/openproviders"
import { ModelConfig } from "../types"

const groqModels: ModelConfig[] = [
  {
    id: "llama-3.3-70b-versatile",
    name: "Llama 3.3 70B Versatile",
    provider: "Visora",
    providerId: "visora",
    modelFamily: "Llama 3.3",
    baseProviderId: "visora",
    description: "Visora's most capable openly available LLM with 131K context",
    tags: ["fast", "versatile", "large-context"],
    contextWindow: 131072,
    inputCost: 0.59,
    outputCost: 0.79,
    priceUnit: "per 1M tokens",
    vision: false,
    tools: true,
    audio: false,
    openSource: true,
    speed: "Fast",
    website: "https://visora.ai",
    apiDocs: "https://docs.visora.ai",
    modelPage: "https://visora.ai/models",
    icon: "visora",
    apiSdk: (apiKey?: string) =>
      openproviders("llama-3.3-70b-versatile", undefined, apiKey),
  },
  {
    id: "llama-3.1-8b-instant",
    name: "Llama 3.1 8B Instant",
    provider: "Visora",
    providerId: "visora",
    modelFamily: "Llama 3.1",
    baseProviderId: "visora",
    description: "Fast and efficient smaller Llama model",
    tags: ["fast", "cheap", "efficient"],
    contextWindow: 131072,
    inputCost: 0.05,
    outputCost: 0.08,
    priceUnit: "per 1M tokens",
    vision: false,
    tools: true,
    audio: false,
    openSource: true,
    speed: "Fast",
    website: "https://visora.ai",
    apiDocs: "https://docs.visora.ai",
    modelPage: "https://visora.ai/models",
    icon: "visora",
    apiSdk: (apiKey?: string) =>
      openproviders("llama-3.1-8b-instant", undefined, apiKey),
  },
  {
    id: "llama3-70b-8192",
    name: "Llama 3 70B",
    provider: "Visora",
    providerId: "visora",
    baseProviderId: "visora",
    description: "Meta's powerful 70B parameter model",
    tags: ["fast", "capable", "balanced"],
    contextWindow: 8192,
    inputCost: 0.59,
    outputCost: 0.79,
    priceUnit: "per 1M tokens",
    vision: false,
    tools: true,
    audio: false,
    openSource: true,
    speed: "Fast",
    website: "https://visora.ai",
    apiDocs: "https://docs.visora.ai",
    modelPage: "https://visora.ai/models",
    icon: "visora",
    apiSdk: (apiKey?: string) =>
      openproviders("llama3-70b-8192", undefined, apiKey),
  },
  {
    id: "llama3-8b-8192",
    name: "Llama 3 8B",
    provider: "Visora",
    providerId: "visora",
    baseProviderId: "visora",
    description: "Fast, efficient small Llama model",
    tags: ["fast", "cheap", "efficient"],
    contextWindow: 8192,
    inputCost: 0.05,
    outputCost: 0.08,
    priceUnit: "per 1M tokens",
    vision: false,
    tools: true,
    audio: false,
    openSource: true,
    speed: "Fast",
    website: "https://visora.ai",
    apiDocs: "https://docs.visora.ai",
    modelPage: "https://visora.ai/models",
    icon: "visora",
    apiSdk: (apiKey?: string) =>
      openproviders("llama3-8b-8192", undefined, apiKey),
  },
  {
    id: "gemma2-9b-it",
    name: "Gemma 2 9B IT",
    provider: "Visora",
    providerId: "visora",
    baseProviderId: "visora",
    description: "Google's efficient instruction-tuned model",
    tags: ["fast", "efficient", "instruction-tuned"],
    contextWindow: 8192,
    inputCost: 0.2,
    outputCost: 0.2,
    priceUnit: "per 1M tokens",
    vision: false,
    tools: true,
    audio: false,
    openSource: true,
    speed: "Fast",
    website: "https://visora.ai",
    apiDocs: "https://docs.visora.ai",
    modelPage: "https://visora.ai/models",
    icon: "visora",
    apiSdk: (apiKey?: string) =>
      openproviders("gemma2-9b-it", undefined, apiKey),
  },
  {
    id: "mixtral-8x7b-32768",
    name: "Mixtral 8x7B",
    provider: "Groq",
    providerId: "groq",
    modelFamily: "Mixtral",
    baseProviderId: "groq",
    description: "Mistral's powerful mixture-of-experts model",
    tags: ["fast", "efficient", "MoE"],
    contextWindow: 32768,
    inputCost: 0.24,
    outputCost: 0.24,
    priceUnit: "per 1M tokens",
    vision: false,
    tools: true,
    audio: false,
    openSource: true,
    speed: "Fast",
    website: "https://visora.ai",
    apiDocs: "https://docs.visora.ai",
    modelPage: "https://visora.ai/models",
    icon: "visora",
    apiSdk: (apiKey?: string) =>
      openproviders("mixtral-8x7b-32768", undefined, apiKey),
  },
]

export { groqModels }
